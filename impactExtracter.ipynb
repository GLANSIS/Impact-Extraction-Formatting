{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2897d1d3",
   "metadata": {},
   "source": [
    "# IMPACT EXTRACTOR:\n",
    "**Description:** The following code will pull impacts from the GLANSIS impact data tables. Furthermore, it will format the impact descriptions into bullet points with in-text citations for GLANSIS Organism Impact Assessments and create a reference section. This code will export an excel file with impacts and a word document with references. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f2cfc",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abb5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              # Manage data tables\n",
    "import requests                  # Pulls HTML code from webpage\n",
    "from bs4 import BeautifulSoup    # HTML parsing\n",
    "import re                        # Edit text strings\n",
    "from docx import Document        # Create and edit Word Document\n",
    "from tkinter import filedialog   # Creates file dialog box\n",
    "import os                        # Opens documents automatically\n",
    "from selenium import webdriver                                     # automate web browser interaction\n",
    "from selenium.webdriver.chrome.options import Options              # use to select 'headless' browser options\n",
    "from selenium.webdriver.common.by import By                        # find elements by HTML id on webpage\n",
    "from selenium.webdriver.support.ui import Select                   # use to automate dropdown selection\n",
    "from selenium.webdriver.support.ui import WebDriverWait            # command driver to wait until web page loaded\n",
    "from selenium.webdriver.support import expected_conditions as EC   # wait until web page condition met\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d6c81",
   "metadata": {},
   "source": [
    "## Enter Species ID\n",
    "Entering an impact ID is optional. The code will grab any impacts IDs after the entered ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73bfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = ''\n",
    "first_impact_id = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf3c22",
   "metadata": {},
   "source": [
    "## Table Extraction and Exportation: \n",
    "Running the following code will pull the impact data and reformat it for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29fd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT!\n",
    "\n",
    "# set URL\n",
    "url = 'https://nas.er.usgs.gov/queries/greatlakes/Impacts/ImpactsInfo.aspx?speciesID=' + species_id\n",
    "\n",
    "# Open web page using a headless Selenium webdriver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(options = chrome_options)\n",
    "driver.get(url)\n",
    "\n",
    "# Find dropdown elements on the web page and select information - TYPE\n",
    "type_dropdown = Select(WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'body_ResultsPerPageDD'))))\n",
    "type_dropdown.select_by_visible_text(str(300))\n",
    "\n",
    "# Get html script from web page and find RefNum\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "# Select the table\n",
    "table = soup.find('table', {\"id\": \"body_myGridView\"})\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n",
    "\n",
    "# Create blank list to hold table data\n",
    "data = []\n",
    "\n",
    "# Extract table information\n",
    "for row in table.find_all('tr')[2:-2]:\n",
    "\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    \n",
    "    row_data = [cell.get_text(strip = True, separator = \" \") for cell in cells]\n",
    "\n",
    "    data.append(row_data)\n",
    "\n",
    "# Convert list to DataFrame\n",
    "impact_table = pd.DataFrame(data[1:], columns = data[0])\n",
    "\n",
    "# Filter rows based on condition\n",
    "if first_impact_id != 'NA':\n",
    "    \n",
    "    # Find row index of first impact id numbe\n",
    "    selected_rows = impact_table[impact_table['Impact ID'] >= first_impact_id]\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Duplicate impact_table\n",
    "    selected_rows = impact_table.copy()\n",
    "\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "selected_rows = selected_rows.copy()\n",
    "\n",
    "# Create empty column\n",
    "selected_rows['NAS_Reference'] = None\n",
    "\n",
    "# Pull cut-and-paste references from NAS\n",
    "for index, row in selected_rows.iterrows():\n",
    "    \n",
    "    # Redo with Selenium\n",
    "    url = 'https://nas.er.usgs.gov/queries/references/ReferenceViewer.aspx?refnum=' + str(row['Reference'])\n",
    "    \n",
    "    # Call url\n",
    "    response = requests.post(url)\n",
    "     \n",
    "    # Scrape the RefNum \n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Get HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find specific tag using id attribute\n",
    "        desired_span_tag = soup.find(\"span\", {\"id\": \"ContentPlaceHolder1_CutPasteRef\"})\n",
    "        \n",
    "        # Fill 'NAS_Reference' column\n",
    "        if desired_span_tag:\n",
    "            \n",
    "            # Pull cut-and-paste reference from HTML\n",
    "            reference = desired_span_tag.get_text(strip = True)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # If error, set reference to error\n",
    "            reference = 'Error'\n",
    "            \n",
    "        # Fill cell\n",
    "        selected_rows.loc[index, 'NAS_Reference'] = reference\n",
    "            \n",
    "# Formula to format citations\n",
    "def format_citation(citation):\n",
    "    \n",
    "    # Extract year\n",
    "    year = re.findall(r'\\d{4}', citation)[0]\n",
    "    \n",
    "    # Extract everything before the period before the year using regex\n",
    "    match = re.match(r'^(.+?)\\.\\s\\d{4}\\.', citation).group(1).strip()\n",
    "    \n",
    "    # Split names portion of reference\n",
    "    ref_parts = match.split(', ')\n",
    "    \n",
    "    # Count name reference parts\n",
    "    n_authors = len(ref_parts) - 1\n",
    "    \n",
    "    # Create in-text citation for impact descriptions\n",
    "    if n_authors == 1:\n",
    "        \n",
    "        # Combinbe first author name with year\n",
    "        in_text_citation = str(ref_parts[0]) + ' ' + str(year)\n",
    "\n",
    "    elif n_authors == 2:\n",
    "\n",
    "        # Check if 'and' appears in the second text in the list\n",
    "        if 'and' in ref_parts[2]:\n",
    "\n",
    "            # Split the second text by space and select the last word\n",
    "            second_author = ref_parts[2].split(' ')[-1].strip()\n",
    "            \n",
    "            # Combine two author names together with year\n",
    "            in_text_citation = str(ref_parts[0]) + ' and ' + str(second_author) + ' ' + str(year)\n",
    "\n",
    "        else:\n",
    "            # In case of comma splice in one-author references - this combines author last name with year\n",
    "            in_text_citation = str(ref_parts[0]) + ' ' + str(year)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Combine lead author with 'et al.' and year\n",
    "        in_text_citation = str(ref_parts[0]) + ' et al. ' + str(year)\n",
    "        \n",
    "    return(in_text_citation)\n",
    "\n",
    "\n",
    "# Create column with in-text citations\n",
    "selected_rows['in_text'] = selected_rows['NAS_Reference'].apply(format_citation)\n",
    "\n",
    "\n",
    "# Function to combine text and additional information, removing the last period from the text\n",
    "def combine_text(row):\n",
    "    \n",
    "    text = row['Impact Description']\n",
    "    \n",
    "    # Remove the last character (period)\n",
    "    if row['Impact Description'].endswith('.'):\n",
    "        row['Impact Description'] = row['Impact Description'][:-1]  \n",
    "        \n",
    "    combined = str(row['Impact Description']) + ' ' + '(' + str(row['in_text']) + ').'\n",
    "        \n",
    "    return combined\n",
    "\n",
    "\n",
    "# Apply the function to each row to create a new column\n",
    "selected_rows['Impact Description'] = selected_rows.apply(combine_text, axis=1)\n",
    "\n",
    "# Reneame columns\n",
    "new_column_names = {'Reference': 'RefNum', 'NAS_Reference': 'Reference'}\n",
    "selected_rows.rename(columns = new_column_names, inplace = True)\n",
    "\n",
    "# Select necessary columns \n",
    "new_column_order = [\"Impact ID\", \"Impact Type\", \"Study Type\", \"Study Location\", \"Impact Description\", \"Geographic Location\", \"RefNum\", \"Reference\"]\n",
    "selected_rows = selected_rows[new_column_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c2023",
   "metadata": {},
   "source": [
    "## Create Excel file with revised impact descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "321289a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path\n",
    "excel_file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\"), (\"All files\", \"*.*\")])\n",
    "\n",
    "# Save Excel file\n",
    "selected_rows.to_excel(excel_file_path, engine='openpyxl', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720e3f1",
   "metadata": {},
   "source": [
    "## Create Word Document with alphabetically ordered references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725eb372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and sort references\n",
    "references = sorted(selected_rows['Reference'])\n",
    "\n",
    "# Create a new Word document\n",
    "doc = Document()\n",
    "\n",
    "# Add a title to the document\n",
    "doc.add_heading('References', level = 1)\n",
    "\n",
    "# Add references to the document\n",
    "for reference in references:\n",
    "    doc.add_paragraph(reference)\n",
    "\n",
    "# Set file path\n",
    "root = Tk()                                         \n",
    "root.attributes(\"-topmost\", True)                   \n",
    "root.withdraw()\n",
    "doc_file_path = filedialog.asksaveasfilename(defaultextension = \".docx\", filetypes = [(\"Word Document\", \"*.docx\")])\n",
    "\n",
    "# Save the document\n",
    "doc.save(doc_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvImpactExtract",
   "language": "python",
   "name": "venvimpactextract"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
